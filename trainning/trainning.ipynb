{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69af166fa2c3df50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T19:13:41.996900704Z",
     "start_time": "2026-02-05T19:13:41.967224143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! ptxas is now reachable.\n",
      "ptxas: NVIDIA (R) Ptx optimizing assembler\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# The specific directory discovered by your search\n",
    "nvcc_bin = \"/home/ritesh/Downloads/ImageSRCNN/.venv/lib/python3.12/site-packages/nvidia/cuda_nvcc/bin\"\n",
    "\n",
    "# Update PATH and add the XLA fallback for extra stability\n",
    "os.environ[\"PATH\"] = nvcc_bin + os.pathsep + os.environ[\"PATH\"]\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_unsafe_fallback_to_driver_on_ptxas_not_found=true'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Verification check\n",
    "import subprocess\n",
    "try:\n",
    "    res = subprocess.run(['ptxas', '--version'], capture_output=True, text=True)\n",
    "    print(\"Success! ptxas is now reachable.\")\n",
    "    print(res.stdout.splitlines()[0])\n",
    "except Exception as e:\n",
    "    print(\"Link failed. Check if the path exists or use tf.config.optimizer.set_jit(False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516ca5403545ceb8",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80a3b636e7b3f323",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T19:13:42.011159785Z",
     "start_time": "2026-02-05T19:13:42.004556044Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c879f7e8d66455",
   "metadata": {},
   "source": [
    "**Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7625120c04f27ade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T19:13:42.017466997Z",
     "start_time": "2026-02-05T19:13:42.012095283Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "IMAGE_SIZE = 256  # Target High Resolution Size\n",
    "DOWNSCALE_FACTOR = 4\n",
    "EPOCHS = 1\n",
    "CHANNELS = 3\n",
    "# Calculate Low Resolution Size\n",
    "LR_SIZE = IMAGE_SIZE // DOWNSCALE_FACTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edc271ce33b676c",
   "metadata": {},
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "374909bc850e0f61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T19:13:42.069703768Z",
     "start_time": "2026-02-05T19:13:42.018258853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 files.\n"
     ]
    }
   ],
   "source": [
    "def process_input(image):\n",
    "    image = image / 255.0\n",
    "\n",
    "    img_lr = tf.image.resize(image, (LR_SIZE, LR_SIZE), method=\"bicubic\")\n",
    "\n",
    "    return img_lr, image # Input (LR), Target (HR)\n",
    "\n",
    "raw_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/home/ritesh/Downloads/ImageSRCNN/trainning/data/train/DIV2K_HR\",\n",
    "    label_mode=None,\n",
    "    seed=123,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Map the processing function\n",
    "train_ds = raw_dataset.map(process_input).prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a146515a64d692e1",
   "metadata": {},
   "source": [
    "**Build the Super Resolution CNN (SRCNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f47adf10494f7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T19:25:38.581618193Z",
     "start_time": "2026-02-05T19:25:38.506980219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SRCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SRCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">51,232</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,403</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m) │        \u001b[38;5;34m15,616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m) │        \u001b[38;5;34m51,232\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │         \u001b[38;5;34m2,403\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,251</span> (270.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m69,251\u001b[0m (270.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,251</span> (270.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m69,251\u001b[0m (270.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_sr_model(upscale_factor=4, channels=3):\n",
    "    inputs = layers.Input(shape=(None, None, channels))\n",
    "\n",
    "    # 1. Upsampling using Bicubic Interpolation to match target size\n",
    "    # (Alternatively, you can use Conv2DTranspose for learnable upsampling)\n",
    "    x = layers.UpSampling2D(size=(upscale_factor, upscale_factor), interpolation='bilinear')(inputs)\n",
    "\n",
    "    # 2. Feature Extraction (Patch extraction and representation)\n",
    "    x = layers.Conv2D(64, (9, 9), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 3. Non-linear mapping\n",
    "    x = layers.Conv2D(32, (5, 5), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 4. Reconstruction\n",
    "    outputs = layers.Conv2D(channels, (5, 5), padding='same', activation='linear')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"SRCNN\")\n",
    "    return model\n",
    "\n",
    "model = get_sr_model(upscale_factor=DOWNSCALE_FACTOR)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c20b0af94d5863",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10acb25bc6e80666",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T19:25:48.733375419Z",
     "start_time": "2026-02-05T19:25:47.026397801Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  7/400\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 22ms/step - loss: 0.1525 - mean_absolute_error: 0.2921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1770319823.159916   26122 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - loss: 0.0188 - mean_absolute_error: 0.0908\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mean_absolute_error']\n",
    ")\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d55cd4",
   "metadata": {},
   "source": [
    "**Visualization & Comparison (Results)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451174e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3805647479.py, line 16)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m# ... (rest of your plotting code)\u001b[39m\n                                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def plot_results(model, dataset, num_samples=3):\n",
    "    # Take a single batch\n",
    "    for lr_batch, hr_batch in dataset.take(1):\n",
    "        \n",
    "        # Check how many images are actually in this batch\n",
    "        batch_size = lr_batch.shape[0]\n",
    "        # Don't try to plot more than we actually have\n",
    "        actual_samples = min(num_samples, batch_size)\n",
    "        \n",
    "        plt.figure(figsize=(15, 5 * actual_samples))\n",
    "        \n",
    "        # Generate Super Resolution images\n",
    "        sr_batch = model.predict(lr_batch)\n",
    "        \n",
    "        for i in range(actual_samples):\n",
    "            # ... (rest of your plotting code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
